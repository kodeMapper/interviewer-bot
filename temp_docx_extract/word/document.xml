<?xml version="1.0" encoding="UTF-8"?>
<w:document xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/main" xmlns:m="http://schemas.openxmlformats.org/officeDocument/2006/math" xmlns:r="http://schemas.openxmlformats.org/officeDocument/2006/relationships" xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:v="urn:schemas-microsoft-com:vml" xmlns:w10="urn:schemas-microsoft-com:office:word" xmlns:a="http://schemas.openxmlformats.org/drawingml/2006/main" xmlns:pic="http://schemas.openxmlformats.org/drawingml/2006/picture" xmlns:wp="http://schemas.openxmlformats.org/drawingml/2006/wordprocessingDrawing">
<w:body>
    <w:bookmarkStart w:id="20" w:name="header" />
    <w:bookmarkEnd w:id="20" />
    <w:bookmarkStart w:id="60" w:name="content" />
    <w:bookmarkStart w:id="59" w:name="X320c2752747b854f1d938141a457bf088ec8ed4" />
    <w:p><w:pPr><w:pStyle w:val="Heading1" /></w:pPr><w:r><w:t xml:space="preserve">AI-Driven Adaptive Technical Interview Bot: Design and Implementation</w:t></w:r></w:p>
    <w:bookmarkStart w:id="26" w:name="overall-system-architecture" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">1. Overall System Architecture</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">A production interview bot is typically built as a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">distributed, microservices-based system</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">rather than a single monolith</w:t></w:r><w:hyperlink r:id="rId21"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[1]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId22"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[2]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. This decoupled design allows independent scaling and updates of components. For example, separate services can handle speech-to-text (ASR), natural language understanding (NLU), question retrieval, answer evaluation, and state management. Each service can be containerized (e.g. Docker) and orchestrated via Kubernetes or similar tools</w:t></w:r><w:hyperlink r:id="rId22"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[2]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId23"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[3]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. APIs (REST/JSON or gRPC) connect these microservices: the frontend/UI (web or voice app) calls backend endpoints to ask questions or submit answers. Large models (LLMs, embeddings) run in dedicated inference services (e.g. using TorchServe, FastAPI, or cloud endpoints). A</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">vector database</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(Milvus, Weaviate, Pinecone, etc.) stores question embeddings for semantic search</w:t></w:r><w:hyperlink r:id="rId24"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[4]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId22"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[2]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. An orchestration layer (e.g. Apache Airflow, Temporal, or Step Functions) can coordinate multi-step pipelines (e.g. logging a turn, triggering model inference, updating knowledge state)</w:t></w:r><w:hyperlink r:id="rId23"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[3]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">In practice, the system supports</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">real-time</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">and</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">asynchronous</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">modes. In real-time mode, the candidate speaks or types answers in an ongoing session: audio streams to ASR (e.g. Whisper) and text flows to Q-selection and scoring modules immediately. Latency must be low (e.g. sub-second) so the bot feels responsive. In asynchronous mode, the candidate’s responses (voice or text) are submitted offline and processed later (for batch scoring or analysis). Backend queues (e.g. Kafka, RabbitMQ) can buffer tasks between services. Continuous integration/deployment pipelines ensure models (and data schemas) are versioned and updated safely</w:t></w:r><w:hyperlink r:id="rId22"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[2]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="Compact" /><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Microservices vs. Monolith:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A microservices design splits functionality into independent services, which can be scaled and updated without redeploying the whole system</w:t></w:r><w:hyperlink r:id="rId25"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[5]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId21"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[1]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. While a monolith is simpler to start, microservices (with container orchestration) are preferred for enterprise-grade systems</w:t></w:r><w:hyperlink r:id="rId25"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[5]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId22"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[2]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="Compact" /><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">APIs &amp; Model Serving:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Each AI component (ASR, embeddings, LLM) exposes an API. For example, a FastAPI endpoint may load a Transformer model and serve inference requests. This separates model runtime from business logic.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="Compact" /><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Vector Databases:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Questions are embedded into semantic vectors (via a sentence or cross-encoder) and indexed in a vector DB</w:t></w:r><w:hyperlink r:id="rId24"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[4]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. At runtime, the bot can find semantically similar questions or answers by performing nearest-neighbor searches in the vector space</w:t></w:r><w:hyperlink r:id="rId24"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[4]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="Compact" /><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1001" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Orchestration:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A workflow engine manages interview state transitions. For instance, it might enforce: “After scoring an answer, update the candidate’s skill profile and then select the next question.” AI-specific cloud-native designs treat models as first-class services</w:t></w:r><w:hyperlink r:id="rId22"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[2]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId23"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[3]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">, allowing CI/CD and monitoring (e.g. automated drift detection, model versioning, logging).</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="26" />
    <w:bookmarkStart w:id="28" w:name="skill-based-interview-initialization" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">2. Skill-Based Interview Initialization</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Upon starting an interview, the bot parses the candidate’s self-reported skills and experience level. Skills are normalized (e.g. “ML” → “Machine Learning”) and matched against a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">skill taxonomy or ontology</w:t></w:r><w:hyperlink r:id="rId27"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[6]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. A skill taxonomy is a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /><w:iCs /></w:rPr><w:t xml:space="preserve">hierarchical classification</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">of related skills</w:t></w:r><w:hyperlink r:id="rId27"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[6]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">, so “Python” might map to sub-skills like “OOP,” “Data Structures,” “Async Libraries,” etc. In practice, the system can use a combination of rule-based matching and embedding similarity: for each input skill string, look up canonical names (e.g. using an internal mapping or pretrained NER model) and expand to related concepts via the taxonomy.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Next, each skill is calibrated for</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">difficulty</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">based on the candidate’s level (fresher, mid, senior). For example, a senior Python developer implies deeper topics (metaprogramming, concurrency) than a fresher. This sets the initial parameters of the interview policy (e.g. starting difficulty score, topic choice). The system might use a simple rule (e.g.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">if experience &gt;5y then difficulty += 2</w:t></w:r><w:r><w:t xml:space="preserve">) or an ML regression on profile features. In summary, the bot builds an</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /><w:iCs /></w:rPr><w:t xml:space="preserve">initial knowledge profile</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">that maps each declared skill to an estimated mastery (or baseline difficulty), to seed the adaptive questioning.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="28" />
    <w:bookmarkStart w:id="30" w:name="question-bank-knowledge-representation" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">3. Question Bank &amp; Knowledge Representation</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">The</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">question bank</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">is a core data component. Questions are stored in a structured database with fields like:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">{id, text, solution, skill_tags, difficulty, format, ...}</w:t></w:r><w:r><w:t xml:space="preserve">. Each question’s</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /><w:iCs /></w:rPr><w:t xml:space="preserve">text</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">is indexed in two ways: (1) traditional indexing (full-text or key tags), and (2)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">semantic embeddings</w:t></w:r><w:r><w:t xml:space="preserve">. We use a sentence encoder (e.g. Sentence-BERT) to convert each question into a fixed vector, then store these in a vector database</w:t></w:r><w:hyperlink r:id="rId24"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[4]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. At runtime, to find a question on a particular topic or similar content, the bot generates a query vector and retrieves nearest neighbors by cosine similarity</w:t></w:r><w:hyperlink r:id="rId24"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[4]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. This enables recall of semantically related questions even if keywords differ.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Questions are also organized by</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">topics and prerequisites</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">via a knowledge graph. In a knowledge graph approach, each question is linked to concept nodes, and edges indicate prerequisite relationships</w:t></w:r><w:hyperlink r:id="rId29"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[7]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. For example, “implementing a LRU cache” might depend on “hash tables” and “doubly linked lists.” This graph lets the bot avoid asking a question if a prerequisite hasn’t been covered. It also helps sequence questions: e.g. teach basic sorting before asking about algorithm optimizations. As Kop et al. describe, knowledge-graph methods explicitly model</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /><w:iCs /></w:rPr><w:t xml:space="preserve">domain structure</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">and concept dependencies</w:t></w:r><w:hyperlink r:id="rId29"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[7]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">, which guides content selection.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">There are two ways to generate questions:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">static</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">and</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">dynamic</w:t></w:r><w:r><w:t xml:space="preserve">. Static questions are hand-crafted and vetted (stored as above). Dynamic question generation uses an LLM or template engine to create novel questions on the fly. For example, one could prompt a GPT to “generate a medium-difficulty Python OOP question,” then check the output. Dynamic generation expands the question pool but requires careful filtering to ensure correctness and uniqueness. In both cases, the system tracks which questions have been asked (by ID or by semantic hash) to</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">avoid repetition</w:t></w:r><w:r><w:t xml:space="preserve">. Before re-asking or generating a similar question, the bot checks the candidate’s history (using the vector store) to ensure new questions. This prevents leaks or duplicates: the interview won’t accidentally present the same question wording twice.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="30" />
    <w:bookmarkStart w:id="34" w:name="dataset-design-training-data" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">4. Dataset Design &amp; Training Data</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Building and training the AI components requires diverse data. Key dataset types include:</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">-</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Interview Transcripts:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Text (or audio) logs of real or mock interviews. These contain the questions asked and the candidate’s answers. Transcripts are used to train dialogue management and response evaluation models.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">-</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Question–Answer Pairs:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Curated or synthetic Q/A pairs (including solutions and multiple example answers) are needed to teach the system what correct and incorrect answers look like. These can come from textbooks, forums, or be generated by large LMs.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">-</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Candidate Performance Logs:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Records of candidate actions (e.g. time per question, code submissions, answer correctness) help in modeling pacing and scoring.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">-</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Rubrics &amp; Scoring Annotations:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Each question may have an expected answer rubric. Human experts annotate model answers or actual candidate answers with scores and rationales. This labeled data trains evaluation models.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Datasets must be</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">labeled</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">for difficulty and content. For example, each question can be tagged as “easy/medium/hard,” and answers can be annotated with concept coverage or depth. In practice, labeling is often performed by domain experts using guidelines (rubrics) to ensure consistency. For instance, experts might rate answers 1–5 for correctness or identify which key points are covered. As Leong et al. note, creating comprehensive rubrics and calibrating raters is essential to minimize subjective bias</w:t></w:r><w:hyperlink r:id="rId31"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[8]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">Since real interview data is scarce,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">synthetic data</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">generation is often used. One can use LLMs (GPT-4, PaLM, etc.) to automatically create large volumes of Q/A examples. For instance, prompts can generate variations of a coding problem or plausible candidate answers. These can bootstrap initial training; later replaced with real data as it comes in. An MVP might start with a few thousand Q/A pairs and a few dozen transcripts; a full system may require tens of thousands of questions and hundreds of hours of labeled interviews.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Bias and fairness</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">are critical. Human interviewers (and therefore their annotations) often exhibit unintended biases. Studies show factors like age, gender, or race can skew human hiring decisions</w:t></w:r><w:hyperlink r:id="rId32"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[9]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. We must actively mitigate this. In practice, that means diversifying the training corpus and auditing model performance across demographic groups. All candidate data must be handled per privacy laws. For example, GDPR requires consent for recording interviews and secures PII</w:t></w:r><w:hyperlink r:id="rId33"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[10]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="34" />
    <w:bookmarkStart w:id="41" w:name="deep-learning-models-used" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">5. Deep Learning Models Used</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Different AI models serve different pipeline stages. Common choices include:</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Skill Parsing &amp; Embedding:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A text encoder (e.g. BERT/RoBERTa) can embed the candidate’s skill list or resume summary. These embeddings are matched against a skill taxonomy to normalize input. For example, Sentence-BERT could encode “Python, Web Dev” and identify nearest skills in an ontology.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Question Selection Policy:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">We can use deep learning here in multiple ways. A</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">policy network</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(e.g. an RL agent) can learn to pick questions given the current state. Alternatively, a pair of encoders could rank candidate questions by relevance: one encoder for state+history, another for question text, scoring via dot-product. Reinforcement-learning models (DQN, policy gradient) can be trained to maximize a long-term reward (such as candidate mastery). For instance, Lin and Liu formulate adaptive testing as an MDP and find that a DQN-based selector outperforms traditional item-response methods</w:t></w:r><w:hyperlink r:id="rId35"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[11]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Answer Evaluation:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Transformer models are used to judge answers. Options include: 1)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Encoder-only</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">models to embed the candidate’s answer and compare it to the solution (e.g. compute cosine similarity between SBERT embeddings of answer vs. reference); 2)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Decoder-only</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(LLM) models to generate a score or feedback via prompting; 3)</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Encoder–Decoder</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">models (T5/BART) fine-tuned on Q→score. In practice, all three are used. For example, one approach is to extract a BERT embedding of the answer and feed it to a regression/classifier (as shown by Xie et al. achieving QWK≈0.817 on essay scoring with a frozen BERT+contrastive regressor</w:t></w:r><w:hyperlink r:id="rId36"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[12]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">). Another is to fine-tune a GPT- or Llama-based model end-to-end on answer-scoring labels</w:t></w:r><w:hyperlink r:id="rId37"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[13]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. Hybrid methods (e.g. using LLM prompting plus retrieved exemplars) can also be applied.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Follow-up Generation:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">After an answer, the bot may need to probe deeper. A generative LLM (GPT, Claude, etc.) is used here. For instance, given the question, answer, and current context, an LLM can be prompted to “ask a clarifying question” or “give gentle hints.” Large chat models (with system prompt guidance) excel at such conversational Q/A.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Knowledge Tracing Models:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">To maintain the candidate’s skill state, we can use models like Bayesian Knowledge Tracing (BKT) or Deep Knowledge Tracing (DKT).</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">BKT</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">treats each skill as a hidden binary state (mastered or not) and updates its probability with each answer</w:t></w:r><w:hyperlink r:id="rId38"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[14]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. It uses parameters for initial mastery, learning, slip (careless error), and guess</w:t></w:r><w:hyperlink r:id="rId39"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[15]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">DKT</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">replaces this with an RNN (LSTM) that ingests the sequence of (question, correctness) pairs and outputs skill mastery vectors</w:t></w:r><w:hyperlink r:id="rId40"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[16]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. Piech et al. showed DKT can learn complex patterns and outperform BKT by modeling latent state with neural nets</w:t></w:r><w:hyperlink r:id="rId40"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[16]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. In practice, we may choose BKT for its simplicity or DKT for its flexibility, or even hybrid.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1002" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Curriculum and Bandit Learning:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The bot’s policy can be refined by curriculum learning (start easy, then gradually harder) and multi-armed bandit methods. A bandit algorithm might treat each topic as an “arm” and select questions to balance exploitation (test known strengths) vs. exploration (probe uncertain areas). Over many interviews, a contextual bandit could learn which sequences yield fastest mastery.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="41" />
    <w:bookmarkStart w:id="44" w:name="answer-evaluation-scoring" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">6. Answer Evaluation &amp; Scoring</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">The bot must evaluate answers</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">semantically</w:t></w:r><w:r><w:t xml:space="preserve">, not just by keywords. Techniques include:</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1003" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Semantic Similarity:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Compute the similarity between the candidate’s answer and the reference solution. For example, encode both with a Transformer (SBERT, etc.) and score by cosine similarity. This captures meaning even if different wording is used.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1003" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Concept Coverage &amp; Partial Credit:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Answers often deserve partial credit. One approach is to detect presence of key concepts. For instance, the rubric might list “use of loop” and “proper variable naming.” The model checks which rubric points appear. Neural models can be trained (supervised on human-scored answers) to regress to a partial score.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1003" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Reasoning Depth:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">To assess depth, we might prompt an LLM to judge if the candidate showed step-by-step reasoning. For example, chain-of-thought prompting can produce an explanation or score. A well-tuned model can assign higher scores to answers that include logical justifications.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1003" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Handling Wrong or Vague Answers:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">If an answer is off-topic or nonsensical, we assign a low score. Techniques like perplexity (how well the answer fits a language model) or NER/ontology checks (does it mention relevant entities) help detect garbage. We may also check for</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">hallucinations</w:t></w:r><w:r><w:t xml:space="preserve">: if the answer contains factual claims, we could use a retrieval step to verify them or flag unlikely assertions.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1003" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Confidence &amp; Calibration:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Model outputs (softmax probabilities or regression uncertainty) should be calibrated. For instance, if the model is 90% confident an answer is correct, that should empirically match a 90% success rate. Calibration techniques or an auxiliary confidence predictor can be applied.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1003" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Rubric-based vs Neural:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">A fully</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">rubric-based</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">approach explicitly encodes scoring rules. For example, the RATAS framework translates rubrics into a decision tree and uses an LLM to fill it</w:t></w:r><w:hyperlink r:id="rId42"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[17]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. This yields interpretable scores (points per criterion). By contrast,</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">neural scoring</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(embedding/regression or fine-tuning) learns end-to-end from data. In practice, hybrid solutions work well: e.g. an LLM can be prompted with the rubric to “explain which criteria are met”</w:t></w:r><w:hyperlink r:id="rId42"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[17]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">, and then a deterministic score is computed. As Patil et al. observe, purely neural methods can lack transparency, so combining them with rubric structures improves explainability</w:t></w:r><w:hyperlink r:id="rId42"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[17]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1003" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Transformer Scoring Examples:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">As reviewed by Kübler et al., transformer-based scoring can be done via zero-shot LLM prompts, embedding+regression, or end-to-end fine-tuning</w:t></w:r><w:hyperlink r:id="rId36"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[12]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId37"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[13]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. For instance, Jiang &amp; Bosch used GPT-4 prompting to score short answers (achieving a respectable QWK~0.68 with no training</w:t></w:r><w:hyperlink r:id="rId43"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[18]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">). Embedding-based methods (frozen encoders + neural regressor) have reached top public benchmarks</w:t></w:r><w:hyperlink r:id="rId36"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[12]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. Fine-tuning a decoder model on labeled data also works well (Ormerod &amp; Kwako achieve QWK~0.76–0.79 by fine-tuning Llama-family models</w:t></w:r><w:hyperlink r:id="rId37"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[13]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">). In our system, we might use several of these in ensemble.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="44" />
    <w:bookmarkStart w:id="46" w:name="adaptive-question-selection" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">7. Adaptive Question Selection</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Deciding</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /><w:iCs /></w:rPr><w:t xml:space="preserve">what to ask next</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">is the heart of adaptivity. In our framework, this is formulated as a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">sequential decision problem</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(often modeled with reinforcement learning or knowledge tracing). Key elements:</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">State Representation:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The bot’s state captures what it “knows” about the candidate. Concretely, this could be a vector of estimated mastery probabilities for each concept or skill (from a BKT or DKT model), plus dialogue context (which questions have been asked, recent correctness). For BKT, the state is simply P(mastered) for each skill</w:t></w:r><w:hyperlink r:id="rId38"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[14]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. For DKT, the hidden RNN state encodes the entire interaction history</w:t></w:r><w:hyperlink r:id="rId40"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[16]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. We might also include meta-data like the candidate’s declared experience, speed, and confidence signals.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Actions:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The action space is “select next question (or topic/difficulty level).” The bot could either pick a specific question ID or choose a high-level action (e.g. “increase difficulty” or “switch topic to X”). In an RL setting, each action corresponds to asking a particular question (from the pool compatible with the state).</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Reward:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The reward function encourages learning and accuracy. A simple reward is +1 for a correct answer and 0 for wrong (or penalize wrong). More sophisticated rewards might consider the information gained (e.g. how much the candidate’s mastery estimate changed) or long-term goals (e.g. maximize final score). Meng et al. (2024) formulate the interview path as an MDP: states = knowledge profile, actions = content selection, reward = learning outcome</w:t></w:r><w:hyperlink r:id="rId45"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[19]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. In practice, you could define a reward that is the square of the improvement in estimated skill, or tie it to the eventual candidate success metric.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Policy &amp; RL:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">With this setup, one can train a policy network by RL. For example, Lin &amp; Liu reformulated computerized adaptive testing under RL and found a deep Q-network (DQN) strategy that outperformed traditional information-based item selection</w:t></w:r><w:hyperlink r:id="rId35"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[11]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. This means the bot could learn, via trial interviews, which questions maximize information about the candidate. Alternatively, policy-gradient methods or contextual bandits (where each “arm” is a topic) could be used. Over many iterations, the model learns to ask easier questions first, then harder ones as mastery increases (a form of</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /><w:iCs /></w:rPr><w:t xml:space="preserve">curriculum learning</w:t></w:r><w:r><w:t xml:space="preserve">).</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Knowledge Tracing:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">In tandem, we update the candidate’s estimated mastery after each answer. BKT provides a closed-form Bayes update (accounting for slips/guesses)</w:t></w:r><w:hyperlink r:id="rId38"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[14]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. DKT updates the hidden state via its network. These estimates feed back into the state for the next action. For instance, if after some questions the candidate’s P(mastered) for “recursion” is near 1.0, the bot will shift to another topic.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Mastery vs Guessing:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">BKT explicitly models guessing errors, but in RL terms we can also check mastery by asking multiple questions in a row. If a candidate gets two varying recursion problems correct, it’s unlikely to be luck. We may decrease uncertainty only when answers are consistent. Some implementations add a “confirmatory question” action to verify mastery of a skill.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1004" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Exploration vs Exploitation:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">An adaptive interview must balance exploiting known strengths (asking more questions on a topic already handled well) and exploring unknown weaknesses. This is analogous to the multi-armed bandit trade-off. In practice we might implement an ε-greedy or upper-confidence-bound scheme: e.g. with some probability, try a question from a less-tested skill to gather information. RL inherently learns some exploration (via its stochastic policy or added entropy bonus).</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">In summary, the bot uses a</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">policy-learning model</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(potentially with RL) to decide each next question. The state includes the candidate’s inferred knowledge (via BKT/DKT), and the reward is tied to eliciting informative answers. As Kop et al. explain, one can view the interview path as an MDP where &quot;states represent learner knowledge profiles, actions correspond to content selection, and rewards derive from learning outcomes&quot;</w:t></w:r><w:hyperlink r:id="rId45"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[19]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. For example, Lin &amp; Liu show that a DQN-based strategy learns to pick items that reduce estimation error better than classic methods</w:t></w:r><w:hyperlink r:id="rId35"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[11]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. We apply these ideas to dynamically raise or lower difficulty, switch topics, or drill deeper based on the candidate’s performance.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="46" />
    <w:bookmarkStart w:id="47" w:name="conversation-flow-context-management" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">8. Conversation Flow &amp; Context Management</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Maintaining context over the interview is crucial. We employ both short-term and long-term memory strategies:</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1005" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Short-Term Memory (STM):</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Keep the last several turns (questions and answers) in context. This can simply be a buffer passed to the LLM as part of the prompt. For example, when generating a follow-up, we include the previous Q/A pair to maintain continuity. Techniques like Retrieval-Augmented Generation (RAG) could retrieve relevant past exchanges from a database if the context window is limited.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1005" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Long-Term State:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Beyond the immediate conversation, the bot stores the evolving</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">knowledge state</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(mastery estimates, as in BKT/DKT above). This acts as longer-term memory of what’s been covered. Additionally, non-critical facts (e.g. the candidate’s name or self-descriptions) could be stored in a database so the bot doesn’t re-ask basic info.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1005" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Avoiding Contradictions:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The bot checks consistency: if the candidate said earlier “I have no Java experience,” it won’t later ask for Java-specific details. State flags can mark which topics are active or “off-limits.” Also, if a question was asked, it won’t repeat it. For dialogue, if a user’s answer is unclear, the bot may ask for clarification (“Could you elaborate on your approach?”). The LLM’s natural language capabilities ensure follow-ups sound human-like, avoiding robotic repetition.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1005" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Natural Language Flow:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The system uses a conversational prompt style for the LLM (system and user messages) to keep the tone polite and professional. This includes greetings, guiding phrases, and acknowledgement (“Thank you for that answer”). It may even paraphrase a candidate’s answer back (“I understand you solved it with a loop and a dictionary.”) to confirm understanding, using LLM summarization.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1005" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Clarifications &amp; Follow-ups:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">If the answer is incomplete or mentions an interesting idea, the bot can spontaneously generate a follow-up question (“You mentioned using a loop; could you explain why you chose that data structure?”). The LLM, given context, can craft these seamlessly.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Overall, the bot continuously updates a memory of the interview. Contradictions are avoided by checking stored state before generating a question. For example, if the candidate’s transcript contains an answer, the bot cross-checks it before formulating any reference or next question. This combination of dialogue context and structured state prevents repetitive or contradictory prompts.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="47" />
    <w:bookmarkStart w:id="49" w:name="training-strategy" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">9. Training Strategy</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">The models are trained in stages:</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Pretraining vs Fine-tuning:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">We start with large pretrained language models (e.g. GPT-4, Llama 3, or specialized code models) rather than training from scratch. These models have broad knowledge. We then</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">fine-tune</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">them on our domain data (coding and interview transcripts). For instance, a GPT-like model can be fine-tuned on a corpus of technical Q/A to better suit interview dialogue. Similarly, encoder models can be fine-tuned on our labeled answers for better scoring accuracy.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Offline Training:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Initially, training is done offline using the collected dataset. For RL components, offline simulations can be run: e.g. simulate many candidate profiles and answers to train the Q-selection policy network by backpropagation through game episodes. Supervised models (skill parser, answer scorer) are trained on labeled examples using standard gradient descent.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Online Learning / Human-in-the-Loop:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">After deployment, the system can continue learning. Human reviewers may correct model outputs or annotate new data. For example, if the bot’s scoring disagrees with a human rater, that example is fed back to refine the model. A/B testing of different policies can be done online (e.g. compare two selection strategies). This enables</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /><w:iCs /></w:rPr><w:t xml:space="preserve">continual learning</w:t></w:r><w:r><w:t xml:space="preserve">—periodically re-training models on new interviews to adapt to changing norms or content.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Curriculum Learning:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Training itself can use a curriculum. For example, the Q-selection policy might be trained first on easy question distributions, then gradually introduced to harder cases. This mirrors how the bot will adapt difficulty during interviews.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1006" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Evaluation Metrics:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">We measure performance with both ML metrics and interview-specific KPIs. For scoring models, we might use Quadratic Weighted Kappa or Pearson correlation against human scores</w:t></w:r><w:hyperlink r:id="rId36"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[12]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. For the overall bot, metrics include the accuracy of knowledge estimation (does it predict a user’s proficiency?), interview length, candidate satisfaction (through surveys), and fairness scores across demographics. Psychometric-style validation (e.g. whether model’s scores agree with expert rubrics) is also applied</w:t></w:r><w:hyperlink r:id="rId36"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[12]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. We monitor for model drift (e.g. if scoring patterns gradually deviate from expected baseline)</w:t></w:r><w:hyperlink r:id="rId48"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[20]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="49" />
    <w:bookmarkStart w:id="51" w:name="production-concerns" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">10. Production Concerns</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Deploying a live interview bot brings many engineering and compliance issues:</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Latency &amp; Scaling:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Real-time interactions demand low latency. Models may be large, so we optimize inference (using quantization, distillation, or smaller model variants) to meet response-time budgets (typically &lt;1–2 seconds). We use GPU/TPU for heavy inference (especially Whisper ASR and LLMs), and autoscale these services under load.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Cost Control:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Running large models continuously can be expensive. An open-source-first approach helps control costs (no per-query API fees). We may use proprietary APIs (OpenAI, Azure OpenAI, etc.) only in early prototyping or fallback when hosting isn’t feasible. Caching common inferences and batching requests can save resources.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Monitoring &amp; Drift Detection:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">In production, we log all interactions. We set up automated alerts if model outputs deviate (e.g. scoring distribution shifts, embedding-based retrieval fails). Tools like Prometheus or custom analytics track key metrics. As InfoWorld notes, AI-native deployments include drift monitoring to flag performance degradation</w:t></w:r><w:hyperlink r:id="rId48"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[20]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Security &amp; Privacy:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The system handles sensitive candidate data. All transcripts and answers are securely stored with encryption at rest and in transit. Access controls ensure only authorized components/people see PII. We comply with GDPR and other data laws</w:t></w:r><w:hyperlink r:id="rId33"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[10]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">: candidates must consent to being recorded, and have the “right to be forgotten.” We anonymize or discard personally identifying data when not needed. For example, EU law classifies AI recruiting as “high risk,” so we implement strict bias controls and data protection</w:t></w:r><w:hyperlink r:id="rId50"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[21]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId33"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[10]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Anti-Cheating Measures:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Because candidates might try to game the system (using external AI, plagiarizing answers, etc.), we build countermeasures. We randomize non-critical question order to thwart memorization. We analyze answer patterns (e.g. timing, code copy-paste detection) to flag suspicious behavior. We might include</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">honeypot questions</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(that require creative answers). For coding answers, integration with a plagiarism-check service (like MOSS) can detect identical submissions. These measures reduce the risk of answer memorization or tool-assisted cheating.</w:t></w:r></w:p>
    <w:p><w:pPr><w:numPr><w:ilvl w:val="0" /><w:numId w:val="1007" /></w:numPr></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Compliance &amp; Safety:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Under regulations (e.g. EU AI Act, US EEOC guidelines), AI hiring tools must be fair and explainable. We log decision rationales (e.g. which rubric points were met) to enable audits. The system includes override buttons for human interviewers to step in if needed. As a legal source advises, “algorithms used by AI in recruitment […] may inadvertently perpetuate bias” and must be carefully guarded</w:t></w:r><w:hyperlink r:id="rId50"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[21]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. We proactively test for protected-class biases in model outcomes and adjust training if any are found.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="51" />
    <w:bookmarkStart w:id="52" w:name="example-pseudo-implementation" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">11. Example Pseudo-Implementation</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">Below is a high-level pseudocode and data schema illustrating how the components interact during a live voice interview. This is not full runnable code but outlines the flow:</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="SourceCode" /></w:pPr><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve"># Load models (Python example)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">import whisper, numpy as np</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">from sentence_transformers import SentenceTransformer</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">asr_model = whisper.load_model(&quot;medium&quot;)   # OpenAI Whisper for ASR</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">embed_model = SentenceTransformer(&#39;all-MiniLM-L6-v2&#39;)  # Encoder for semantic retrieval</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve"># (Assume pre-loaded: question_selector, answer_evaluator, state_manager)</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve"># Data schemas (simplified)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">class Question:</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    def __init__(self, id, text, skills, difficulty, solution):</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.id = id</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.text = text</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.skills = skills      # e.g., [&quot;Python&quot;, &quot;OOP&quot;]</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.difficulty = difficulty  # e.g., 0.7</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.solution = solution  # reference answer or rubric</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">class InterviewState:</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    def __init__(self, candidate_id, skills_mastery):</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.candidate_id = candidate_id</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.skills_mastery = skills_mastery  # dict skill -&gt; P(master)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.asked_questions = []             # list of question IDs asked</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.conversation_history = []        # list of (Q_id, answer_text, score)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    def update(self, question, answer_text, score):</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        # update mastery (e.g. via BKT/DKT)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        # pseudo: self.skills_mastery = update_mastery(self.skills_mastery, question, score)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.asked_questions.append(question.id)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        self.conversation_history.append((question.id, answer_text, score))</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve"># Example interview loop</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">state = InterviewState(candidate_id=123, skills_mastery={&#39;Python&#39;: 0.5, &#39;ML&#39;: 0.3})</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">while True:</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    # Select next question based on current state</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    question = question_selector.select_next_question(state)  # could use RL policy</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    print(&quot;Bot:&quot;, question.text)</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    # Capture candidate answer via microphone (here we simulate by loading a file)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    audio = record_audio_from_microphone(duration=10)  # capture 10 sec audio</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    asr_result = asr_model.transcribe(audio)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    answer_text = asr_result[&quot;text&quot;]</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    print(&quot;Candidate:&quot;, answer_text)</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    # Evaluate answer</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    score, confidence = answer_evaluator.evaluate(answer_text, question.solution)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    print(f&quot;Score: {score:.1f} (conf={confidence:.2f})&quot;)</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    # Update interview state</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    state.update(question, answer_text, score)</w:t></w:r><w:r><w:br /></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    # Check end condition (e.g. number of questions or time)</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">    if state.finished():   # e.g., 15 questions or all skills covered</w:t></w:r><w:r><w:br /></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">        break</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Flow Explanation:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">First, we transcribe the candidate’s speech to text using Whisper. Next, the</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">question_selector</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(which may use a neural policy or simple rules) picks the next</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">Question</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">object based on</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">state</w:t></w:r><w:r><w:t xml:space="preserve">. The question is asked (printed or spoken). We record the candidate’s answer (audio), transcribe it, and pass the text to</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">answer_evaluator</w:t></w:r><w:r><w:t xml:space="preserve">. The evaluator could, for example, embed the answer and compare to the solution, or prompt an LLM to score it. We then update</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">state</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(e.g. via a BKT update or neural network) to reflect the new mastery estimates. This loop continues until termination.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Model Flow Diagram (textual):</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">1.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Skill Initialization:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Candidate provides skills → NLP normalization → initialize</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">InterviewState</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">(skill masteries).</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">2.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Question Selection:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">State → question selector model (possibly RL policy) → next question.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">3.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Ask Question:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Question.text → spoken to candidate via TTS or displayed in UI.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">4.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Receive Answer:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Candidate speaks → audio captured → Whisper ASR → answer text.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">5.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Answer Evaluation:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Evaluate(answer text, question.solution) → numerical score + feedback.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">6.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">State Update:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Use score to update mastery probabilities (BKT/DKT) and conversation history.</w:t></w:r><w:r><w:br /></w:r><w:r><w:t xml:space="preserve">7.</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Loop:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Return to step 2 until interview end.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Data Interaction:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">The</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">Question</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">objects (from the question DB) come with precomputed embeddings stored in a vector DB. The</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">question_selector</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">may query this DB or use a policy network. The</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:rStyle w:val="VerbatimChar" /></w:rPr><w:t xml:space="preserve">InterviewState</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">may also be persisted per user in a database, enabling resume if interrupted. All interactions are logged for later analysis.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="52" />
    <w:bookmarkStart w:id="58" w:name="Xa49f5f962d53ce6a611c459caf2e38d9787c9da" />
    <w:p><w:pPr><w:pStyle w:val="Heading2" /></w:pPr><w:r><w:t xml:space="preserve">12. Industry Practices &amp; Real-World Constraints</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:r><w:t xml:space="preserve">In practice, fully autonomous adaptive bots are still emerging. Some research prototypes (e.g. Anthropic’s “Interviewer”</w:t></w:r><w:hyperlink r:id="rId53"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[22]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">) use a multi-stage pipeline (planning a rubric, conducting interviews, then analyzing transcripts). Major hiring platforms today (HackerRank, Codility, etc.) mostly use static or scripted assessments (often with human oversight) rather than free-form conversational bots.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">However, the hiring industry is rapidly evolving. Many companies now</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">expect AI usage in interviews</w:t></w:r><w:r><w:t xml:space="preserve">. For example, Rippling and Meta allow candidates to use AI tools during coding rounds</w:t></w:r><w:hyperlink r:id="rId54"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[23]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. A recent survey found</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">startups</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">adding AI-assisted interview stages and phasing out “hand-coding” questions</w:t></w:r><w:hyperlink r:id="rId55"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[24]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. This shift emphasizes</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:rPr><w:i /><w:iCs /></w:rPr><w:t xml:space="preserve">AI-collaboration skills</w:t></w:r><w:r><w:t xml:space="preserve">. At the same time, big companies remain cautious: they still heavily rely on algorithmic questions, though they are re-designing them to defeat simple LLM answers</w:t></w:r><w:hyperlink r:id="rId56"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[25]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">. Interviewers are also changing their style (asking more follow-ups and engaging) to counteract cheating</w:t></w:r><w:hyperlink r:id="rId57"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[26]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Feasibility vs. Theory:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">While the above architecture is theoretically sound, practical systems face pitfalls. LLMs can hallucinate or make subtle mistakes; relying on them for key decisions can be risky. Real-time voice transcription can fail on accents or noise. Maintaining rigorous fairness (per regulatory guidelines) is challenging. For instance, EU rules classify AI hiring tools as “high risk”</w:t></w:r><w:hyperlink r:id="rId50"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[21]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">, requiring strict bias audits and candidate consent. Moreover, automated systems must be scrutinized by legal teams – as Greenberg Traurig notes, AI recruiting must not violate anti-discrimination laws or GDPR</w:t></w:r><w:hyperlink r:id="rId50"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[21]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId33"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[10]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Common Failure Modes:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Empirically, the bot might incorrectly assess an answer (overestimate or miss a key point), leading to a skewed difficulty trajectory. It might ask an inapplicable question if the skill state is wrong. Network or GPU outages can cause downtime. A poorly calibrated scoring model might demotivate candidates by unfair grading. These are mitigated by extensive testing, fallbacks (e.g. static questions if the bot “gets stuck”), and human-in-the-loop oversight.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:t xml:space="preserve">In summary, the described system outlines a cutting-edge approach to adaptive technical interviewing, combining ASR (Whisper), transformer-based AI, RL policies, and modern MLOps. It leans on open-source building blocks (Whisper, open LLMs, sentence-transformers, vector DBs) for full control and on-demand fine-tuning. Proprietary services might be used early on (e.g. GPT-4 for bootstrapping plan generation), but the goal is an open, extensible system. By integrating these components with careful data design and compliance checks, one can build a highly technical, adaptive interview bot as described above.</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:r><w:rPr><w:b /><w:bCs /></w:rPr><w:t xml:space="preserve">Sources:</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Industry articles and academic research on AI-driven interviewing and tutoring inform these design principles</w:t></w:r><w:hyperlink r:id="rId25"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[5]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId22"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[2]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId24"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[4]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId27"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[6]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId36"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[12]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId37"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[13]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId38"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[14]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId40"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[16]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId45"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[19]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId35"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[11]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId42"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[17]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId32"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[9]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId50"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[21]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId53"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[22]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId54"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[23]</w:t></w:r></w:hyperlink><w:hyperlink r:id="rId56"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[25]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve">, ensuring the solution reflects real-world practices and cutting-edge methods.</w:t></w:r></w:p>
    <w:bookmarkEnd w:id="58" />
    <w:bookmarkEnd w:id="59" />
    <w:bookmarkEnd w:id="60" />
    <w:p><w:r><w:pict><v:rect style="width:0;height:1.5pt" o:hralign="center" o:hrstd="t" o:hr="t" /></w:pict></w:r></w:p>
    <w:bookmarkStart w:id="76" w:name="citations" />
    <w:p><w:pPr><w:pStyle w:val="FirstParagraph" /></w:pPr><w:hyperlink r:id="rId21"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[1]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId25"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[5]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Monolithic vs. Microservices Architecture | IBM</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId61"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://www.ibm.com/think/topics/monolithic-vs-microservices</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId22"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[2]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId23"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[3]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId48"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[20]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Understanding AI-native cloud: from microservices to model-serving | InfoWorld</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId62"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://www.infoworld.com/article/4111954/understanding-ai-native-cloud-from-microservices-to-model-serving.html</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId24"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[4]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Vector Databases: Architecture Deep Dive | Medium</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId63"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://medium.com/@nay1228/unveiling-the-inner-workings-of-vector-databases-a-technical-deep-dive-eac76f0b1779</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId27"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[6]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Skill Taxonomy 101: The Complete Guide to Building a Future-Ready Tech Workforce</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId64"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://prismforce.com/blog/skill-taxonomy</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId29"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[7]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId45"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[19]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Deep knowledge tracing and cognitive load estimation for personalized learning path generation using neural network architecture - PMC</w:t></w:r><w:r><w:t xml:space="preserve"> </w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId65"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://pmc.ncbi.nlm.nih.gov/articles/PMC12246154/</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId31"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[8]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId32"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[9]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">vikramr.com</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId66"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">http://www.vikramr.com/pubs/ICCV_Interpreting_and_Explaining_Visual_Artificial_Intelligence_Models.pdf</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId33"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[10]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId50"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[21]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Use of AI in Recruitment and Hiring – Considerations for EU and US Companies | Insights | Greenberg Traurig LLP</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId67"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://www.gtlaw.com/en/insights/2025/5/use-of-ai-in-recruitment-and-hiring-considerations-for-eu-and-us-companies</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId35"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[11]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">An adaptive testing item selection strategy via a deep reinforcement learning approach - PubMed</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId68"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://pubmed.ncbi.nlm.nih.gov/39271633/</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId36"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[12]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId37"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[13]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId43"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[18]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Crash course in transformer-era automated scoring</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId69"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://psychometrics.ai/llm-based-automated-scoring-overview</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId38"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[14]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId39"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[15]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Bayesian knowledge tracing - Wikipedia</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId70"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://en.wikipedia.org/wiki/Bayesian_knowledge_tracing</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId40"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[16]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">stanford.edu</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId71"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://stanford.edu/~cpiech/bio/papers/deepKnowledgeTracing.pdf</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId42"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[17]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">RATAS: A Generative AI Framework for Explainable and Scalable Automated Answer Grading</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId72"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://arxiv.org/html/2505.23818v1</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId53"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[22]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">Introducing Anthropic Interviewer \ Anthropic</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId73"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://www.anthropic.com/research/anthropic-interviewer</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId54"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[23]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">How Technical Interviews Are Evolving with AI</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId74"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://formation.dev/blog/how-technical-interviews-are-evolving-with-ai/</w:t></w:r></w:hyperlink></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId55"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[24]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId56"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[25]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:hyperlink r:id="rId57"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">[26]</w:t></w:r></w:hyperlink><w:r><w:t xml:space="preserve"> </w:t></w:r><w:r><w:t xml:space="preserve">How is AI changing technical interviews at FAANG+? We have the data, and it&#39;s not much at all : r/leetcode</w:t></w:r></w:p>
    <w:p><w:pPr><w:pStyle w:val="BodyText" /></w:pPr><w:hyperlink r:id="rId75"><w:r><w:rPr><w:rStyle w:val="Hyperlink" /></w:rPr><w:t xml:space="preserve">https://www.reddit.com/r/leetcode/comments/1nqc0r4/how_is_ai_changing_technical_interviews_at_faang/</w:t></w:r></w:hyperlink></w:p>
    <w:bookmarkEnd w:id="76" />
    <w:sectPr>
      <w:footnotePr>
        
                
        <w:numRestart w:val="eachSect" />
        
              
      </w:footnotePr>
    </w:sectPr>
  </w:body>
</w:document>
